{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xtevensab007/Modelos_1/blob/main/fase-1/02_modelos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7XmyXvJBDISL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "227e77e0-053e-4b36-a41b-b5e68384dd28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/experimental/enable_hist_gradient_boosting.py:16: UserWarning: Since version 1.0, it is not needed to import enable_hist_gradient_boosting anymore. HistGradientBoostingClassifier and HistGradientBoostingRegressor are now stable and can be normally imported from sklearn.ensemble.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Bibliotecas utilizadas\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import warnings\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.experimental import enable_hist_gradient_boosting\n",
        "from sklearn.ensemble import HistGradientBoostingRegressor\n",
        "\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "# Carga de datos\n",
        "data_train = pd.read_csv('https://docs.google.com/spreadsheets/d/e/2PACX-1vQHU9r-osSfdm1EQ1qT4SqM13kdFN5ELQStnSx-n4jOzSr4jxrg-YMG4bCe9W5Kkw1qelHxSKrfZlMi/pub?gid=1834913949&single=true&output=csv')\n",
        "data_test = pd.read_csv('https://docs.google.com/spreadsheets/d/e/2PACX-1vSOz7KZRcRa_l7f4QF5wk5W5LXvAZZBMgr5hdVGt2d_Pxm8n4fqnPQ4n6dSLv0H2nkNx19SKUzGZhX4/pub?gid=854072752&single=true&output=csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# nombres de las columnas test\n",
        "column_names = data_test.columns\n",
        "\n",
        "print(column_names)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20S-r5ypJ5JF",
        "outputId": "6c1deb4f-2e70-4403-dc69-c2a66fbb13c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['id', 'belongs_to_collection', 'budget', 'genres', 'homepage',\n",
            "       'imdb_id', 'original_language', 'original_title', 'overview',\n",
            "       'popularity', 'poster_path', 'production_companies',\n",
            "       'production_countries', 'release_date', 'runtime', 'spoken_languages',\n",
            "       'status', 'tagline', 'title', 'Keywords', 'cast', 'crew'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelos\n",
        "###Modelo con Random Forest\n",
        "\n",
        "Para este primer acercamiento se analizará primordialmente  las variables de ('budget', 'popularity', 'runtime') puesto se les considera los factores mas influyentes."
      ],
      "metadata": {
        "id": "SDt08UvmHs7I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# columnas\n",
        "columnas = ['budget', 'popularity', 'runtime']\n",
        "X_train = data_train[columnas]\n",
        "y_train = data_train['revenue']\n",
        "\n",
        "X_test = data_test[columnas]\n",
        "\n",
        "# Filtrar valores nulos\n",
        "X_train = X_train.fillna(0)\n",
        "y_train = y_train.fillna(0)\n",
        "X_test = X_test.fillna(0)\n",
        "\n",
        "# Limpiar y transformar las columnas con formato incorrecto\n",
        "for columna in columnas:\n",
        "    X_train[columna] = pd.to_numeric(X_train[columna].astype(str).replace('[^\\d.]', '', regex=True), errors='coerce')\n",
        "    X_test[columna] = pd.to_numeric(X_test[columna].astype(str).replace('[^\\d.]', '', regex=True), errors='coerce')\n",
        "\n",
        "# Eliminar valores nulos en X_train y y_train\n",
        "filas_nulas_entrenamiento = X_train[X_train.isnull().any(axis=1) | y_train.isnull()]\n",
        "X_train = X_train.drop(filas_nulas_entrenamiento.index)\n",
        "y_train = y_train.drop(filas_nulas_entrenamiento.index)\n",
        "\n",
        "# Dividir datos de entrenamiento\n",
        "X_train_entrenamiento, X_train_evaluacion, y_train_entrenamiento, y_train_evaluacion = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "# Crear modelo de bosque aleatorio\n",
        "modelo = RandomForestRegressor(n_estimators=500, max_depth=10, random_state=42)\n",
        "\n",
        "# Entrenar el modelo\n",
        "modelo.fit(X_train_entrenamiento, y_train_entrenamiento)\n",
        "\n",
        "# Realizar predicciones en el conjunto de evaluación\n",
        "predicciones_evaluacion = modelo.predict(X_train_evaluacion)\n",
        "\n",
        "# Error Cuadrático Medio (MSE)\n",
        "mse = mean_squared_error(y_train_evaluacion, predicciones_evaluacion)\n",
        "print(f'Error Cuadrático Medio en el conjunto de evaluación: {mse}')\n",
        "\n",
        "# Error Porcentual Absoluto Medio (MAPE)\n",
        "mape = mean_absolute_error(y_train_evaluacion, predicciones_evaluacion) / y_train_evaluacion.mean() * 100\n",
        "print(f'Error Porcentual Absoluto Medio en el conjunto de evaluación: {mape}%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yx68jBdzIffV",
        "outputId": "44ce3bb4-aa26-4bb4-952d-26532844b44b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error Cuadrático Medio en el conjunto de evaluación: 1229573966511585.0\n",
            "Error Porcentual Absoluto Medio en el conjunto de evaluación: 83.00649221608263%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Es evidente que el error es demasiado elevado, con locual se concluye que a pesar de que parece que estas variables son las mas influyentes a primera vista, no son suficientemente descriptivas en un ambito general.\n",
        "\n",
        "A partir de de este entendimiento, se integrarán mas columnas al modelo, esperando que mejore la calidad de la predicción\n"
      ],
      "metadata": {
        "id": "t6uyJm_7UYbV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# columnas\n",
        "columnas_seleccionadas = ['budget', 'genres', 'original_language', 'popularity', 'production_companies',\n",
        "                           'production_countries', 'release_date', 'runtime', 'spoken_languages', 'cast', 'revenue']\n",
        "\n",
        "data_train = data_train[columnas_seleccionadas]\n",
        "data_test = data_test[columnas_seleccionadas[:-1]]  # Excluir 'revenue' de las columnas de prueba\n",
        "\n",
        "# valores nulos\n",
        "data_train = data_train.fillna(0)\n",
        "data_test = data_test.fillna(0)\n",
        "\n",
        "# Limpiar\n",
        "columnas_numericas = ['budget', 'popularity', 'runtime']\n",
        "for columna in columnas_numericas:\n",
        "    data_train[columna] = pd.to_numeric(data_train[columna].astype(str).replace('[^\\d.]', '', regex=True), errors='coerce')\n",
        "    data_test[columna] = pd.to_numeric(data_test[columna].astype(str).replace('[^\\d.]', '', regex=True), errors='coerce')\n",
        "\n",
        "# columnas categóricas\n",
        "columnas_categoricas = ['genres', 'original_language', 'production_companies', 'production_countries', 'spoken_languages', 'cast']\n",
        "data_train[columnas_categoricas] = data_train[columnas_categoricas].astype(str)\n",
        "data_test[columnas_categoricas] = data_test[columnas_categoricas].astype(str)\n",
        "\n",
        "# Codificación one-hot\n",
        "encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
        "\n",
        "# Aplicar codificación one-hot\n",
        "data_train_encoded = pd.DataFrame(encoder.fit_transform(data_train[columnas_categoricas]))\n",
        "data_train_encoded.columns = data_train_encoded.columns.astype(str)\n",
        "\n",
        "data_test_encoded = pd.DataFrame(encoder.transform(data_test[columnas_categoricas]))\n",
        "data_test_encoded.columns = data_test_encoded.columns.astype(str)\n",
        "\n",
        "# Concatenar las columnas\n",
        "data_train_final = pd.concat([data_train[columnas_numericas], data_train_encoded], axis=1)\n",
        "data_test_final = pd.concat([data_test[columnas_numericas], data_test_encoded], axis=1)\n",
        "\n",
        "# Dividir datos\n",
        "X_train_entrenamiento, X_train_evaluacion, y_train_entrenamiento, y_train_evaluacion = train_test_split(data_train_final, data_train['revenue'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Crear modelo de Random Forest\n",
        "modelo = RandomForestRegressor(n_estimators=500, max_depth=10, random_state=42)\n",
        "\n",
        "# Entrenar modelo\n",
        "modelo.fit(X_train_entrenamiento, y_train_entrenamiento)\n",
        "\n",
        "# Realizar predicciones\n",
        "predicciones_evaluacion = modelo.predict(X_train_evaluacion)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GILa1zAgR70Y",
        "outputId": "c8ed5763-6cc4-4976-8fc8-87800072b813"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular el Error Cuadrático Medio (MSE) y Error Porcentual Absoluto Medio (MAPE)\n",
        "mse = mean_squared_error(y_train_evaluacion, predicciones_evaluacion)\n",
        "print(f'Error Cuadrático Medio en el conjunto de evaluación: {mse}')\n",
        "\n",
        "mape = mean_absolute_error(y_train_evaluacion, predicciones_evaluacion) / y_train_evaluacion.mean() * 100\n",
        "print(f'Error Porcentual Absoluto Medio en el conjunto de evaluación: {mape}%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WvJq_uy3aZbz",
        "outputId": "fbbbdfda-85d8-4883-eb52-03b8a5da0d7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error Cuadrático Medio en el conjunto de evaluación: 6616851962288012.0\n",
            "Error Porcentual Absoluto Medio en el conjunto de evaluación: 61.45531854162958%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se puede apreciar un menor porcentaje de error, sin embargo la difecencia es minima y este sigue siendo relativamente alto, a pesar de la inclusión de nuevas variables que parecieran ser mas significativas e influyentes en el valor del dinero recaudado por estas peliculas"
      ],
      "metadata": {
        "id": "dZGPxm5chWw4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###modelo con SVM\n",
        "\n",
        "Se realizará una prueba con el modelo SVM con la intencion de comparar resultados\n"
      ],
      "metadata": {
        "id": "gDGb3DxTi7Hh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  valores nulos\n",
        "data_train = data_train.fillna(0)\n",
        "data_test = data_test.fillna(0)\n",
        "\n",
        "# Limpiar\n",
        "columnas_numericas = ['budget', 'popularity', 'runtime']\n",
        "for columna in columnas_numericas:\n",
        "    data_train[columna] = pd.to_numeric(data_train[columna].astype(str).replace('[^\\d.]', '', regex=True), errors='coerce')\n",
        "    data_test[columna] = pd.to_numeric(data_test[columna].astype(str).replace('[^\\d.]', '', regex=True), errors='coerce')\n",
        "\n",
        "# Convertir categóricas\n",
        "columnas_categoricas = ['genres', 'original_language', 'production_companies', 'production_countries', 'spoken_languages', 'cast']\n",
        "data_train[columnas_categoricas] = data_train[columnas_categoricas].astype(str)\n",
        "data_test[columnas_categoricas] = data_test[columnas_categoricas].astype(str)\n",
        "\n",
        "# Codificación one-hot\n",
        "encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
        "\n",
        "# Aplicar codificación one-hot\n",
        "data_train_encoded = pd.DataFrame(encoder.fit_transform(data_train[columnas_categoricas]))\n",
        "data_train_encoded.columns = data_train_encoded.columns.astype(str)\n",
        "\n",
        "data_test_encoded = pd.DataFrame(encoder.transform(data_test[columnas_categoricas]))\n",
        "data_test_encoded.columns = data_test_encoded.columns.astype(str)\n",
        "\n",
        "# Concatenar las columnas\n",
        "data_train_final = pd.concat([data_train[columnas_numericas], data_train_encoded], axis=1)\n",
        "data_test_final = pd.concat([data_test[columnas_numericas], data_test_encoded], axis=1)\n",
        "\n",
        "# Dividir datos\n",
        "X_train_entrenamiento, X_train_evaluacion, y_train_entrenamiento, y_train_evaluacion = train_test_split(data_train_final, data_train['revenue'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Crear modelo de SVM con un pipeline que incluye imputación de valores nulos\n",
        "modelo = make_pipeline(SimpleImputer(strategy='mean'), SVR())\n",
        "\n",
        "# Entrenar el modelo\n",
        "modelo.fit(X_train_entrenamiento, y_train_entrenamiento)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "id": "Dz3syhEBiwKx",
        "outputId": "a41091c3-9be3-40f3-d7c6-5e200b9b3114"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('simpleimputer', SimpleImputer()), ('svr', SVR())])"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;simpleimputer&#x27;, SimpleImputer()), (&#x27;svr&#x27;, SVR())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;simpleimputer&#x27;, SimpleImputer()), (&#x27;svr&#x27;, SVR())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVR</label><div class=\"sk-toggleable__content\"><pre>SVR()</pre></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Realizar predicciones\n",
        "predicciones_evaluacion = modelo.predict(X_train_evaluacion)\n",
        "\n",
        "# Error Cuadrático Medio (MSE) y Error Porcentual Absoluto Medio (MAPE)\n",
        "mse = mean_squared_error(y_train_evaluacion, predicciones_evaluacion)\n",
        "mape = mean_absolute_error(y_train_evaluacion, predicciones_evaluacion) / y_train_evaluacion.mean() * 100\n",
        "\n",
        "print(f'Error Cuadrático Medio en el conjunto de evaluación: {mse}')\n",
        "print(f'Error Porcentual Absoluto Medio en el conjunto de evaluación: {mape:.2f}%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5txv3hgke7B",
        "outputId": "5d238931-b065-4a32-ead1-075026f6d11b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error Cuadrático Medio en el conjunto de evaluación: 1.9866483239291616e+16\n",
            "Error Porcentual Absoluto Medio en el conjunto de evaluación: 93.01%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## conclusiones\n",
        "\n",
        "De la presente evaluación es posible concluir que el modelo de Support Vector Machine (SVM) con el conjunto de datos proporcionado parece tener un rendimiento significativamente inferior en compración al modelo de Random Forest. Existe un multiplicidad de factores que pueden contribuir a esta discrepancia, uno de estos radica en la sensibilidad a la escala de las características en SVM, del mismo modo, la necesidad de ajustar adecuadamente los hiperparámetros y el manejo de valores nulos. Podríamos afirmar entonces que en comparación con Random Forest, que puede ser más robusto y menos sensible a la escala, es recomendable centrarse en ajustar y mejorar el modelo de Random Forest, considerando entonces la exploración de diferentes configuraciones de hiperparámetros y asegurándose de que los datos se preparen adecuadamente previo a entrenar el modelo.\n"
      ],
      "metadata": {
        "id": "QHLHDN8Mlo5Z"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8bZnDoaWmd0C"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}